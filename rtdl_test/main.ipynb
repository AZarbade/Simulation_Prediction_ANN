{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# Docs: https://yura52.github.io/delu/0.0.4/reference/api/zero.improve_reproducibility.html\n",
    "zero.improve_reproducibility(seed=1024)\n",
    "task_type = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LD</th>\n",
       "      <th>Velocity (km/s)</th>\n",
       "      <th>a (degrees)</th>\n",
       "      <th>$ (degrees)</th>\n",
       "      <th>DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.43447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.84327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.15</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0.77519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LD  Velocity (km/s)  a (degrees)  $ (degrees)       DI\n",
       "0   1             1.00          -60            0  0.41420\n",
       "1   4             1.25           90           30  0.43447\n",
       "2   4             2.15          -30           30  0.84327\n",
       "3   1             1.50           30            0  0.67618\n",
       "4   2             2.15           30           45  0.77519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert task_type in ['binclass', 'multiclass', 'regression']\n",
    "\n",
    "y_all = df['DI'].astype('float32' if task_type == 'regression' else 'int64').to_numpy()\n",
    "X_all = df.drop('DI', axis=1).astype('float32').to_numpy()\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
    "    X_all, y_all, train_size=0.8\n",
    ")\n",
    "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
    "    X['train'], y['train'], train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    [[4.0, 0.25, -45.0, 0.0], [2.0, 1.81, -60.0, 7...\n",
       "test     [[1.0, 1.81, 30.0, 30.0], [2.0, 0.5, 0.0, 0.0]...\n",
       "val      [[2.0, 1.0, 0.0, 30.0], [4.0, 1.25, -90.0, 30....\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    [0.02226, 0.23859, 0.30764, 0.00691, 0.70507, ...\n",
       "test     [0.7193, 0.17152, 0.70523, 0.43667, 0.40425, 0...\n",
       "val      [0.39144, 0.43447, 0.40332, 0.41014, 0.02402, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not the best way to preprocess features, but enough for the demonstration\n",
    "preprocess = sklearn.preprocessing.StandardScaler()\n",
    "preprocess.fit(X['train'])\n",
    "\n",
    "X = {\n",
    "    k: torch.tensor(preprocess.transform(v), device=device)\n",
    "    for k, v in X.items()\n",
    "}\n",
    "y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! CRUCIAL for neural networks when solving regression problems !!!\n",
    "if task_type == 'regression':\n",
    "    y_mean = y['train'].mean().item()\n",
    "    y_std = y['train'].std().item()\n",
    "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
    "else:\n",
    "    y_std = y_mean = None\n",
    "\n",
    "if task_type != 'multiclass':\n",
    "    y = {k: v.float() for k, v in y.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 1\n",
    "\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=X_all.shape[1],\n",
    "    d_layers=[64, 64, 64],\n",
    "    dropout=0.2,\n",
    "    d_out=d_out,\n",
    ")\n",
    "lr = 0.0003\n",
    "weight_decay = 0.0\n",
    "\n",
    "# model = rtdl.ResNet.make_baseline(\n",
    "#     d_in=X_all.shape[1],\n",
    "#     d_main=128,\n",
    "#     d_intermidiate=256,\n",
    "#     dropout_first=0.2,\n",
    "#     dropout_second=0.0,\n",
    "#     n_blocks=2,\n",
    "#     d_out=d_out,\n",
    "# )\n",
    "# lr = 0.001\n",
    "# weight_decay = 0.0\n",
    "\n",
    "# model = rtdl.FTTransformer.make_default(\n",
    "#     n_num_features=X_all.shape[1],\n",
    "#     cat_cardinalities=None,\n",
    "#     last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
    "#     d_out=d_out,\n",
    "# )\n",
    "\n",
    "# === ABOUT CATEGORICAL FEATURES ===\n",
    "# IF you use MLP, ResNet or any other simple feed-forward model (NOT transformer-based model)\n",
    "# AND there are categorical features\n",
    "# THEN you have to implement a wrapper that handles categorical features.\n",
    "# The example below demonstrates how it can be achieved using rtdl.CategoricalFeatureTokenizer.\n",
    "# ==================================\n",
    "# 1. When you have both numerical and categorical features, you should prepare you data like this:\n",
    "#    (X_num<float32>, X_cat<int64>) instead of X<float32>\n",
    "#    Each column in X_cat should contain values within the range from 0 to <(the number of unique values in column) - 1>;\n",
    "#    use sklean.preprocessing.OrdinalEncoder to achieve this;\n",
    "# 2. Prepare a list of so called \"cardinalities\":\n",
    "#    cardinalities[i] = <the number of unique values of the i-th categorical feature>\n",
    "# 3. See the commented example below and adapt it for your needs.\n",
    "#\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         n_num_features: int,\n",
    "#         cat_tokenizer: rtdl.CategoricalFeatureTokenizer,\n",
    "#         mlp_kwargs: Dict[str, Any],\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.cat_tokenizer = cat_tokenizer\n",
    "#         self.model = rtdl.MLP.make_baseline(\n",
    "#             d_in=n_num_features + cat_tokenizer.n_tokens * cat_tokenizer.d_token,\n",
    "#             **mlp_kwargs,\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x_num, x_cat):\n",
    "#         return self.model(\n",
    "#             torch.cat([x_num, self.cat_tokenizer(x_cat).flatten(1, -1)], dim=1)\n",
    "#         )\n",
    "#\n",
    "# model = Model(\n",
    "#     # `None` means \"Do not transform numerical features\"\n",
    "#     # `d_token` is the size of embedding for ONE categorical feature\n",
    "#     X_num_all.shape[1],\n",
    "#     rtdl.CategoricalFeatureTokenizer(cardinalities, d_token, True, 'uniform'),\n",
    "#     mlp_kwargs,\n",
    "# )\n",
    "# Then the model should be used as `model(x_num, x_cat)` instead of of `model(x)`.\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    ")\n",
    "loss_fn = (\n",
    "    F.binary_cross_entropy_with_logits\n",
    "    if task_type == 'binclass'\n",
    "    else F.cross_entropy\n",
    "    if task_type == 'multiclass'\n",
    "    else F.mse_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.2947\n"
     ]
    }
   ],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num, x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(X[part], 1024):\n",
    "        prediction.append(apply_model(batch))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "\n",
    "    if task_type == 'binclass':\n",
    "        prediction = np.round(scipy.special.expit(prediction))\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    elif task_type == 'multiclass':\n",
    "        prediction = prediction.argmax(1)\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    else:\n",
    "        assert task_type == 'regression'\n",
    "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "# Docs: https://yura52.github.io/delu/reference/api/zero.data.IndexLoader.html\n",
    "batch_size = 32\n",
    "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "# Docs: https://yura52.github.io/delu/reference/api/zero.ProgressTracker.html\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 1 (batch) 0 (loss) 1.0061\n",
      "(epoch) 1 (batch) 5 (loss) 1.1991\n",
      "(epoch) 1 (batch) 10 (loss) 1.1380\n",
      "(epoch) 1 (batch) 15 (loss) 0.8603\n",
      "(epoch) 1 (batch) 20 (loss) 0.8749\n",
      "(epoch) 1 (batch) 25 (loss) 1.1549\n",
      "Epoch 001 | Validation score: 0.2584 | Test score: 0.2722 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 2 (batch) 0 (loss) 0.8908\n",
      "(epoch) 2 (batch) 5 (loss) 1.0080\n",
      "(epoch) 2 (batch) 10 (loss) 0.9535\n",
      "(epoch) 2 (batch) 15 (loss) 0.7217\n",
      "(epoch) 2 (batch) 20 (loss) 0.7865\n",
      "(epoch) 2 (batch) 25 (loss) 0.8783\n",
      "Epoch 002 | Validation score: 0.2252 | Test score: 0.2361 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 3 (batch) 0 (loss) 0.7059\n",
      "(epoch) 3 (batch) 5 (loss) 0.7493\n",
      "(epoch) 3 (batch) 10 (loss) 0.6161\n",
      "(epoch) 3 (batch) 15 (loss) 0.5001\n",
      "(epoch) 3 (batch) 20 (loss) 0.4258\n",
      "(epoch) 3 (batch) 25 (loss) 0.6713\n",
      "Epoch 003 | Validation score: 0.1655 | Test score: 0.1727 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 4 (batch) 0 (loss) 0.4273\n",
      "(epoch) 4 (batch) 5 (loss) 0.4318\n",
      "(epoch) 4 (batch) 10 (loss) 0.2749\n",
      "(epoch) 4 (batch) 15 (loss) 0.2388\n",
      "(epoch) 4 (batch) 20 (loss) 0.1550\n",
      "(epoch) 4 (batch) 25 (loss) 0.2727\n",
      "Epoch 004 | Validation score: 0.0899 | Test score: 0.0920 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 5 (batch) 0 (loss) 0.1510\n",
      "(epoch) 5 (batch) 5 (loss) 0.1902\n",
      "(epoch) 5 (batch) 10 (loss) 0.1153\n",
      "(epoch) 5 (batch) 15 (loss) 0.1406\n",
      "(epoch) 5 (batch) 20 (loss) 0.0929\n",
      "(epoch) 5 (batch) 25 (loss) 0.1616\n",
      "Epoch 005 | Validation score: 0.0714 | Test score: 0.0682 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 6 (batch) 0 (loss) 0.1531\n",
      "(epoch) 6 (batch) 5 (loss) 0.1062\n",
      "(epoch) 6 (batch) 10 (loss) 0.1147\n",
      "(epoch) 6 (batch) 15 (loss) 0.1276\n",
      "(epoch) 6 (batch) 20 (loss) 0.0832\n",
      "(epoch) 6 (batch) 25 (loss) 0.1310\n",
      "Epoch 006 | Validation score: 0.0675 | Test score: 0.0646 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 7 (batch) 0 (loss) 0.1326\n",
      "(epoch) 7 (batch) 5 (loss) 0.1329\n",
      "(epoch) 7 (batch) 10 (loss) 0.1129\n",
      "(epoch) 7 (batch) 15 (loss) 0.1139\n",
      "(epoch) 7 (batch) 20 (loss) 0.0920\n",
      "(epoch) 7 (batch) 25 (loss) 0.0954\n",
      "Epoch 007 | Validation score: 0.0640 | Test score: 0.0615 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 8 (batch) 0 (loss) 0.1716\n",
      "(epoch) 8 (batch) 5 (loss) 0.1825\n",
      "(epoch) 8 (batch) 10 (loss) 0.0923\n",
      "(epoch) 8 (batch) 15 (loss) 0.1117\n",
      "(epoch) 8 (batch) 20 (loss) 0.1022\n",
      "(epoch) 8 (batch) 25 (loss) 0.1036\n",
      "Epoch 008 | Validation score: 0.0619 | Test score: 0.0588 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 9 (batch) 0 (loss) 0.2033\n",
      "(epoch) 9 (batch) 5 (loss) 0.1138\n",
      "(epoch) 9 (batch) 10 (loss) 0.0701\n",
      "(epoch) 9 (batch) 15 (loss) 0.1309\n",
      "(epoch) 9 (batch) 20 (loss) 0.0767\n",
      "(epoch) 9 (batch) 25 (loss) 0.0922\n",
      "Epoch 009 | Validation score: 0.0596 | Test score: 0.0564 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 10 (batch) 0 (loss) 0.1348\n",
      "(epoch) 10 (batch) 5 (loss) 0.0698\n",
      "(epoch) 10 (batch) 10 (loss) 0.0782\n",
      "(epoch) 10 (batch) 15 (loss) 0.1047\n",
      "(epoch) 10 (batch) 20 (loss) 0.1005\n",
      "(epoch) 10 (batch) 25 (loss) 0.0974\n",
      "Epoch 010 | Validation score: 0.0574 | Test score: 0.0549 <<< BEST VALIDATION EPOCH\n"
     ]
    }
   ],
   "source": [
    "# wandb init\n",
    "config = {\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    # \"kfolds\": 15,\n",
    "}\n",
    "\n",
    "# wandb.init(\n",
    "#     # group=f'impute&OHC&normalization',\n",
    "#     # name=f'fold_{fold}',\n",
    "#     project='testing',\n",
    "#     config=config)\n",
    "\n",
    "n_epochs = config['epochs']\n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "val_scores = []\n",
    "test_scores = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = X['train'][batch_idx]\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % report_frequency == 0:\n",
    "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "\n",
    "    # val_scores.append(val_score)\n",
    "    # test_scores.append(test_score)\n",
    "\n",
    "    # wandb loggers\n",
    "    # wandb.log({\n",
    "    #     # \"train loss\": test_score,\n",
    "    #     \"valid loss\": val_score,\n",
    "    #     \"test loss\": test_score,\n",
    "    #     # \"train rmse\": train_rmse,\n",
    "    #     # \"valid rmse\": valid_rmse,\n",
    "    #     # \"running seed\": running_seed,\n",
    "    #     \"epoch\": epoch,\n",
    "    #     \"batch_idx\": batch_idx\n",
    "    #     })\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break\n",
    "\n",
    "# Close run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n"
     ]
    }
   ],
   "source": [
    "print(model.__class__.__name__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Jan 16 2023, 14:19:54) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9474590b74a0af69805dd9ae5c5f7507ea5c02423851fc75beec586f25071f8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
